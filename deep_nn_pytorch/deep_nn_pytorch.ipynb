{"cells":[{"cell_type":"markdown","id":"4e959aab","metadata":{"id":"4e959aab"},"source":["# Deep Neural Network com Pytorch"]},{"cell_type":"markdown","id":"3f1cf0b6","metadata":{"id":"3f1cf0b6"},"source":["# Sumário\n","## Semana 1\n","### 1.1 [Tensores 1D](#tensores-1d)\n","### 1.2 [Tensores Bidimensionais](#tensores-bidimensionais)\n","### 1.3 [Derivativos no Pytorch](#derivativos-no-pytorch)\n","### 1.4 [Conjunto de Dados Simples](#conjunto-de-dados-simples)\n","### 1.5 [Conjunto de Dados](#conjunto-de-dados)\n","\n","## Semana 2\n","### 2.1 [Regressão Linear em 1D](#regressão-linear-em-1d)\n","### 2.2 [Treinamento de Regressão Linear](#treinamento-de-regressão-linear)\n","### 2.3 [Gradiente Descendente e Custo](#gradiente-descendente-e-custo)\n","### 2.4 [Pytorch Slope](#pytorch-slope)\n","### 2.5 [Treinamento de Regressão Linear (repetição)](#treinamento-de-regressão-linear-repetição)\n","### 2.6 [Gradiente Descendente Estocástico e o Carregador de Dados](#gradiente-descendente-estocástico-e-o-carregador-de-dados)\n","### 2.7 [Mini-Batch Gradient Descent](#mini-batch-gradient-descent)\n","### 2.8 [Otimização no Pytorch](#otimização-no-pytorch)\n","### 2.9 [Treinamento, Validação e Divisão de Dados](#treinamento-validação-e-divisão-de-dados)\n","\n","## Semana 3\n","### 3.1 [Regressão Linear Múltipla](#regressão-linear-múltipla)\n","### 3.2 [Regressão Linear de Múltiplas Saídas](#regressão-linear-de-múltiplas-saídas)\n","### 3.3 [Regressão Logística para Classificação](#regressão-logística-para-classificação)\n","\n","## Semana 4\n","### 4.1 [Previsão Softmax](#previsão-softmax)\n","### 4.2 [Função Softmax](#função-softmax)\n","### 4.3 [Softmax Pytorch](#softmax-pytorch)\n","### 4.4 [Redes Neurais Rasas](#redes-neurais-rasas)\n","\n","## Semana 5\n","### 5.1 [Redes Neurais Profundas](#redes-neurais-profundas)\n","### 5.2 [Desistência](#desistência)\n","### 5.3 [Pesos e Inicialização da Rede Neural](#pesos-e-inicialização-da-rede-neural)\n","### 5.4 [Gradient Descent com Momentum](#gradient-descent-com-momentum)\n","### 5.5 [Normalização em Lote](#normalização-em-lote)\n","\n","## Semana 6\n","### 6.1 [Convolução](#convolução)\n","### 6.2 [Funções de Ativação e Max Polling](#funções-de-ativação-e-max-polling)\n","### 6.3 [Vários Canais de Entrada e Saída](#vários-canais-de-entrada-e-saída)\n","### 6.4 [Rede Neural Convolucional](#rede-neural-convolucional)\n","### 6.5 [Modelos de Visão de Lanterna](#modelos-de-visão-de-lanterna)"]},{"cell_type":"markdown","id":"d5b75b48","metadata":{"id":"d5b75b48"},"source":["## Semana 1"]},{"cell_type":"markdown","id":"3896b479","metadata":{"id":"3896b479"},"source":["### Tensores 1D"]},{"cell_type":"markdown","source":["Em PyTorch, tensores são estruturas fundamentais que representam dados multi-dimensionais, semelhantes a arrays ou matrizes em outras linguagens. Eles são a base para a construção e manipulação de modelos de aprendizado de máquina e redes neurais profundas. Aqui estão alguns pontos importantes sobre tensores em PyTorch:\n","\n","1. **Similaridade com NumPy:** PyTorch tensores são semelhantes aos arrays do NumPy e, muitas vezes, podem ser convertidos de um para o outro. Isso facilita a integração com bibliotecas científicas em Python.\n","\n","2. **Suporte a GPU:** PyTorch permite a computação em GPUs para acelerar operações. Os tensores podem ser movidos para uma GPU para aproveitar o poder de processamento paralelo.\n","\n","3. **Operações Matemáticas:** PyTorch fornece uma ampla variedade de operações matemáticas que podem ser aplicadas a tensores. Isso inclui operações aritméticas, funções trigonométricas, álgebra linear, entre outras.\n","\n","4. **Autograd:** Uma característica fundamental é o sistema de autograd, que automaticamente calcula gradientes para tensores. Isso é crucial para a otimização de modelos de aprendizado de máquina.\n","\n","5. **Criação de Tensores:** Você pode criar tensores de várias maneiras, seja inicializando-os com valores específicos, gerando números aleatórios, ou a partir de dados existentes.\n","\n","Exemplo de criação de um tensor em PyTorch:\n","\n","```python\n","import torch\n","\n","# Criando um tensor com valores específicos\n","tensor_exemplo = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","\n","print(tensor_exemplo)\n","```\n","\n","Este é um conceito básico, e há muito mais para explorar ao trabalhar com tensores em PyTorch, especialmente ao construir e treinar redes neurais profundas. Se tiver mais perguntas ou se quiser abordar aspectos específicos, sinta-se à vontade para perguntar!"],"metadata":{"id":"tOBB2-AOYAXP"},"id":"tOBB2-AOYAXP"},{"cell_type":"markdown","source":["Tensores 1D em PyTorch são estruturas de dados unidimensionais que podem armazenar uma sequência de elementos. Esses tensores são semelhantes a vetores ou listas unidimensionais em outras linguagens de programação. Eles são úteis para representar dados ao longo de uma única dimensão, como séries temporais, uma linha de pixels de uma imagem ou um conjunto de valores.\n","\n","Aqui está um exemplo de como criar e trabalhar com um tensor 1D em PyTorch:\n","\n","```python\n","import torch\n","\n","# Criando um tensor 1D\n","tensor_1d = torch.tensor([1, 2, 3, 4, 5])\n","\n","# Acessando elementos do tensor\n","print(tensor_1d[0])  # Saída: 1\n","print(tensor_1d[2])  # Saída: 3\n","\n","# Operações matemáticas em tensores 1D\n","tensor_resultado = tensor_1d * 2\n","print(tensor_resultado)  # Saída: tensor([2, 4, 6, 8, 10])\n","```\n","\n","Neste exemplo, `tensor_1d` é um tensor 1D contendo os valores de 1 a 5. Você pode acessar elementos individualmente e realizar operações matemáticas diretamente nos tensores.\n","\n","Os tensores 1D são frequentemente usados em problemas onde os dados estão organizados de forma linear, e são a base para a construção de estruturas de dados mais complexas, como matrizes bidimensionais (tensores 2D) e tensores de ordens superiores."],"metadata":{"id":"nNz_UKZWZnXW"},"id":"nNz_UKZWZnXW"},{"cell_type":"markdown","id":"1099db48","metadata":{"id":"1099db48"},"source":["### Tensores Bidimensionais"]},{"cell_type":"markdown","source":["Tensores bidimensionais em PyTorch são estruturas de dados que representam matrizes, ou seja, arranjos retangulares de elementos organizados em duas dimensões. Eles são comumente utilizados para representar dados tabulares, imagens, ou qualquer outra informação que possa ser organizada em linhas e colunas.\n","\n","Aqui está um exemplo básico de criação e manipulação de um tensor bidimensional em PyTorch:\n","\n","```python\n","import torch\n","\n","# Criando um tensor bidimensional (matriz)\n","tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","\n","# Acessando elementos do tensor bidimensional\n","print(tensor_2d[0, 1])  # Saída: 2 (linha 0, coluna 1)\n","\n","# Operações matemáticas em tensores bidimensionais\n","tensor_resultado = tensor_2d * 2\n","print(tensor_resultado)\n","# Saída:\n","# tensor([[ 2,  4,  6],\n","#         [ 8, 10, 12],\n","#         [14, 16, 18]])\n","```\n","\n","Neste exemplo, `tensor_2d` é uma matriz 3x3 com elementos de 1 a 9. Você pode acessar elementos individualmente usando índices de linha e coluna, e realizar operações matemáticas diretamente nos tensores bidimensionais.\n","\n","Tensores bidimensionais são frequentemente usados em tarefas de processamento de imagens, onde cada elemento da matriz pode representar um pixel. Eles também são essenciais para a construção e treinamento de modelos de aprendizado de máquina, especialmente redes neurais profundas, onde as entradas muitas vezes são representadas por tensores bidimensionais."],"metadata":{"id":"e70I0U5jlGLT"},"id":"e70I0U5jlGLT"},{"cell_type":"code","source":["## Esses são apenas alguns exemplos.\n","# Criando dois tensores bidimensionais\n","tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","tensor_b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n","\n","# Soma de tensores\n","soma = tensor_a + tensor_b\n","print(\"Soma:\")\n","print(soma)\n","\n","# Subtração de tensores\n","subtracao = tensor_a - tensor_b\n","print(\"\\nSubtração:\")\n","print(subtracao)\n","\n","# Multiplicação de tensores (element-wise)\n","multiplicacao_elementwise = tensor_a * tensor_b\n","print(\"\\nMultiplicação (element-wise):\")\n","print(multiplicacao_elementwise)\n","\n","# Multiplicação de tensores (produto matricial)\n","produto_matricial = torch.matmul(tensor_a, tensor_b.T)  # Transpondo tensor_b para alinhar dimensões*\n","print(\"\\nProduto Matricial:\")\n","print(produto_matricial)\n","\n","# Operações de redução (somando elementos ao longo das colunas)\n","soma_colunas = torch.sum(tensor_a, dim=0)\n","print(\"\\nSoma das Colunas:\")\n","print(soma_colunas)\n","\n","# Operações de broadcast (somando uma constante a cada elemento)\n","tensor_soma_constante = tensor_a + 10\n","print(\"\\nSoma com Constante:\")\n","print(tensor_soma_constante)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyEWNWAamvnZ","executionInfo":{"status":"ok","timestamp":1706640146364,"user_tz":180,"elapsed":317,"user":{"displayName":"Alysson G.","userId":"08554535039832716170"}},"outputId":"275ee068-991f-425b-f62d-88197c3d5520"},"id":"lyEWNWAamvnZ","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Soma:\n","tensor([[ 8, 10, 12],\n","        [14, 16, 18]])\n","\n","Subtração:\n","tensor([[-6, -6, -6],\n","        [-6, -6, -6]])\n","\n","Multiplicação (element-wise):\n","tensor([[ 7, 16, 27],\n","        [40, 55, 72]])\n","\n","Produto Matricial:\n","tensor([[ 50,  68],\n","        [122, 167]])\n","\n","Soma das Colunas:\n","tensor([5, 7, 9])\n","\n","Soma com Constante:\n","tensor([[11, 12, 13],\n","        [14, 15, 16]])\n"]}]},{"cell_type":"markdown","source":["Os tensores tridimensionais (tensores 3D) são utilizados para representar dados que possuem uma organização tridimensional, como volumes de imagens ou séries temporais multivariadas. Vamos criar alguns exemplos de tensores 3D em PyTorch:"],"metadata":{"id":"FaxXbiy9rwWK"},"id":"FaxXbiy9rwWK"},{"cell_type":"code","source":["# Criando um tensor 3D (volume)\n","tensor_3d = torch.tensor([[[1, 2, 3],[4, 5, 6]],\n","                          [[7, 8, 9], [10, 11, 12]],\n","                          [[13, 14, 15], [16, 17, 18]]])\n","\n","# Acessando elementos do tensor 3D\n","print(\"Acessando um elemento:\")\n","print(tensor_3d[1, 0, 2])  # Saída: 9 (depth 1, linha 0, coluna 2)\n","\n","# Operações matemáticas em tensores 3D\n","tensor_resultado = tensor_3d * 2\n","print(\"\\nMultiplicação por 2:\")\n","print(tensor_resultado)\n","\n","# Operações de redução (somando elementos ao longo das dimensões)\n","soma_dim1 = torch.sum(tensor_3d, dim=1)\n","print(\"\\nSoma ao Longo da Dimensão 1:\")\n","print(soma_dim1)\n","\n","# Operações de broadcast (somando uma constante a cada elemento)\n","tensor_soma_constante = tensor_3d + 10\n","print(\"\\nSoma com Constante:\")\n","print(tensor_soma_constante)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qKjIklfLnmdS","executionInfo":{"status":"ok","timestamp":1706640222941,"user_tz":180,"elapsed":438,"user":{"displayName":"Alysson G.","userId":"08554535039832716170"}},"outputId":"4f5ecc14-e6f5-4baa-b7c0-263f55b9bac2"},"id":"qKjIklfLnmdS","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Acessando um elemento:\n","tensor(9)\n","\n","Multiplicação por 2:\n","tensor([[[ 2,  4,  6],\n","         [ 8, 10, 12]],\n","\n","        [[14, 16, 18],\n","         [20, 22, 24]],\n","\n","        [[26, 28, 30],\n","         [32, 34, 36]]])\n","\n","Soma ao Longo da Dimensão 1:\n","tensor([[ 5,  7,  9],\n","        [17, 19, 21],\n","        [29, 31, 33]])\n","\n","Soma com Constante:\n","tensor([[[11, 12, 13],\n","         [14, 15, 16]],\n","\n","        [[17, 18, 19],\n","         [20, 21, 22]],\n","\n","        [[23, 24, 25],\n","         [26, 27, 28]]])\n"]}]},{"cell_type":"markdown","source":["Neste exemplo, tensor_3d representa um volume 3D com dimensões 3x2x3. Você pode acessar elementos individualmente usando índices em cada dimensão, e as operações matemáticas podem ser realizadas de maneira semelhante aos tensores 2D.\n","\n","Os tensores 3D são frequentemente encontrados em problemas de visão computacional para representar volumes de dados tridimensionais, como pilhas de imagens ou volumes médicos. Esses exemplos básicos podem ser expandidos conforme a complexidade do problema que você está enfrentando."],"metadata":{"id":"umGcL3m2sY1I"},"id":"umGcL3m2sY1I"},{"cell_type":"markdown","id":"83cd8734","metadata":{"id":"83cd8734"},"source":["### Derivativos no Pytorch"]},{"cell_type":"markdown","id":"1577bf91","metadata":{"id":"1577bf91"},"source":["### Conjutno de Dados Simples"]},{"cell_type":"markdown","id":"9e28c20f","metadata":{"id":"9e28c20f"},"source":["### Conjunto de Dados"]},{"cell_type":"markdown","id":"2def1558","metadata":{"id":"2def1558"},"source":["## Semana 2"]},{"cell_type":"markdown","id":"08ac4ec1","metadata":{"id":"08ac4ec1"},"source":["### Regressão Linear em 1D"]},{"cell_type":"markdown","id":"c9736be8","metadata":{"id":"c9736be8"},"source":["### Treinamento de Regressão Linear"]},{"cell_type":"markdown","id":"2422a0e0","metadata":{"id":"2422a0e0"},"source":["### Gradiente Descendent e Custo"]},{"cell_type":"markdown","id":"cb8f2540","metadata":{"id":"cb8f2540"},"source":["### Pytorch Slope"]},{"cell_type":"markdown","id":"0888679c","metadata":{"id":"0888679c"},"source":["### Treinamento de Regressao Linear"]},{"cell_type":"markdown","id":"d9e44a74","metadata":{"id":"d9e44a74"},"source":["### Gradiente Descendente Estocástico e o Carregador de Dados"]},{"cell_type":"markdown","id":"a88a98ad","metadata":{"id":"a88a98ad"},"source":["### Mini-Batch Gradient Descent"]},{"cell_type":"markdown","id":"4984626d","metadata":{"id":"4984626d"},"source":["### Otimização no Pytorch"]},{"cell_type":"markdown","id":"98a58c7d","metadata":{"id":"98a58c7d"},"source":["### Treinamento, Validação e Divisão de Dados"]},{"cell_type":"markdown","id":"8008dfb8","metadata":{"id":"8008dfb8"},"source":["## Semana 3\n","### Regressão Linear Multipla\n","### Regressão Linear de Múltiplas Saídas\n","### Regressão Logística para Classificação\n","\n","## Semana 4\n","### Previsão Softmax\n","### Função Softmax\n","### Softmax Pytorch\n","### Redes Neurais Rasas\n","\n","## Semana 5\n","### Redes Neurais Profundas\n","### Desistência\n","### Pesos e Inicialização da Rede Neural\n","### Gradient Descent com Momentum\n","### Normalização em Lote"]},{"cell_type":"markdown","id":"9cd231f3","metadata":{"id":"9cd231f3"},"source":["## Semana 6"]},{"cell_type":"markdown","id":"0b1a92ea","metadata":{"id":"0b1a92ea"},"source":["### Convolução"]},{"cell_type":"markdown","id":"5704020a","metadata":{"id":"5704020a"},"source":["### Funções de Ativação e Max Polling"]},{"cell_type":"markdown","id":"a358cb5c","metadata":{"id":"a358cb5c"},"source":["### Vários Canais de Entrada e Saída"]},{"cell_type":"markdown","id":"ed65ebd0","metadata":{"id":"ed65ebd0"},"source":["### Rede Neural Convolucional"]},{"cell_type":"markdown","id":"4f55c553","metadata":{"id":"4f55c553"},"source":["### Modelos de Visão de Lanterna"]},{"cell_type":"markdown","id":"12cc4f30","metadata":{"id":"12cc4f30"},"source":["## Modelos de Visão de Lanterna"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"319.238px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}